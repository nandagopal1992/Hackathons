{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train_data.csv\")\n",
    "test = pd.read_csv(\"./test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    98868\n",
       "2    36854\n",
       "1    33585\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i309911/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  app.launch_new_instance()\n",
      "/Users/i309911/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/i309911/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/i309911/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/i309911/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:9: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/i309911/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:10: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "train['cont_1'] = min_max_scaler.fit_transform(train['cont_1'].reshape(-1,1))\n",
    "test['cont_1'] = min_max_scaler.transform(test['cont_1'].reshape(-1,1))\n",
    "\n",
    "train['cont_2'] = min_max_scaler.fit_transform(train['cont_2'].reshape(-1,1))\n",
    "test['cont_2'] = min_max_scaler.transform(test['cont_2'].reshape(-1,1))\n",
    "\n",
    "train['cont_3'] = min_max_scaler.fit_transform(train['cont_3'].reshape(-1,1))\n",
    "test['cont_3'] = min_max_scaler.transform(test['cont_3'].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_list = ['index' , 'connection_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = train.target\n",
    "train = train.drop(drop_list + ['target'] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = test['connection_id']\n",
    "test = test.drop(['connection_id'] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cont_features = train.columns[train.columns.str.startswith('cont')] \n",
    "cat_features = train.columns[train.columns.str.startswith('cat')] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train[cont_features]\n",
    "X_test = test[cont_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc=OneHotEncoder(sparse=False)\n",
    "for col in cat_features:\n",
    "    data=train[[col]].append(test[[col]])\n",
    "    enc.fit(data)\n",
    "    # Fitting One Hot Encoding on train data\n",
    "    temp = enc.transform(train[[col]])\n",
    "    # Changing the encoded features into a data frame with new column names\n",
    "    temp=pd.DataFrame(temp,columns=[(col+\"_\"+str(i)) for i in data[col]\n",
    "            .value_counts().index])\n",
    "    # In side by side concatenation index values should be same\n",
    "    # Setting the index values similar to the X_train data frame\n",
    "    temp=temp.set_index(train.index.values)\n",
    "    # adding the new One Hot Encoded varibales to the train data frame\n",
    "    X_train=pd.concat([X_train,temp],axis=1)\n",
    "    # fitting One Hot Encoding on test data\n",
    "    temp = enc.transform(test[[col]])\n",
    "    # changing it into data frame and adding column names\n",
    "    temp=pd.DataFrame(temp,columns=[(col+\"_\"+str(i)) for i in data[col]\n",
    "            .value_counts().index])\n",
    "    # Setting the index for proper concatenation\n",
    "    temp=temp.set_index(test.index.values)\n",
    "    # adding the new One Hot Encoded varibales to test data frame\n",
    "    X_test=pd.concat([X_test,temp],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ensemble(object):\n",
    "    def __init__(self, n_splits, stacker, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=2016).split(X, y))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "\n",
    "            S_test_i = np.zeros((T.shape[0], self.n_splits))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "\n",
    "                print (\"Fit %s fold %d\" % (str(clf).split('(')[0], j+1))\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict_proba(X_holdout)[:,1]                \n",
    "\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = clf.predict_proba(T)[:,1]\n",
    "            S_test[:, i] = S_test_i.mean(axis=1)\n",
    "\n",
    "        results = cross_val_score(self.stacker, S_train, y, cv=3)\n",
    "        print(\"Stacker score: %.5f\" % (results.mean()))\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        res = self.stacker.predict_proba(S_test)[:,1]\n",
    "        return res , S_train , S_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_params = {}\n",
    "lgb_params['learning_rate'] = 0.02\n",
    "lgb_params['n_estimators'] = 650\n",
    "lgb_params['max_bin'] = 10\n",
    "lgb_params['subsample'] = 0.8\n",
    "lgb_params['subsample_freq'] = 10\n",
    "lgb_params['colsample_bytree'] = 0.8   \n",
    "lgb_params['min_child_samples'] = 500\n",
    "lgb_params['feature_fraction'] = 0.9\n",
    "lgb_params['bagging_freq'] = 1\n",
    "lgb_params['seed'] = 200\n",
    "\n",
    "lgb_params2 = {}\n",
    "lgb_params2['n_estimators'] = 1090\n",
    "lgb_params2['learning_rate'] = 0.02\n",
    "lgb_params2['colsample_bytree'] = 0.3   \n",
    "lgb_params2['subsample'] = 0.7\n",
    "lgb_params2['subsample_freq'] = 2\n",
    "lgb_params2['num_leaves'] = 16\n",
    "\n",
    "lgb_params2['feature_fraction'] = 0.9\n",
    "lgb_params2['bagging_freq'] = 1\n",
    "lgb_params2['seed'] = 200\n",
    "\n",
    "\n",
    "lgb_params3 = {}\n",
    "lgb_params3['n_estimators'] = 1100\n",
    "lgb_params3['max_depth'] = 4\n",
    "lgb_params3['learning_rate'] = 0.02\n",
    "lgb_params3['feature_fraction'] = 0.9\n",
    "lgb_params3['bagging_freq'] = 1\n",
    "lgb_params3['seed'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_model = LGBMClassifier(**lgb_params)\n",
    "\n",
    "lgb_model2 = LGBMClassifier(**lgb_params2)\n",
    "\n",
    "lgb_model3 = LGBMClassifier(**lgb_params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit LGBMClassifier fold 1\n",
      "Fit LGBMClassifier fold 2\n",
      "Fit LGBMClassifier fold 3\n",
      "Fit LGBMClassifier fold 1\n",
      "Fit LGBMClassifier fold 2\n",
      "Fit LGBMClassifier fold 3\n",
      "Fit LGBMClassifier fold 1\n",
      "Fit LGBMClassifier fold 2\n",
      "Fit LGBMClassifier fold 3\n",
      "Stacker score: 0.78097\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression()      \n",
    "stack = Ensemble(n_splits=3,\n",
    "        stacker = log_model,\n",
    "        base_models = (lgb_model, lgb_model2, lgb_model3))        \n",
    "        \n",
    "y_pred , S_train , S_test = stack.fit_predict(train, y_train, test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_model.fit(S_train, y_train)\n",
    "y_pred = log_model.predict(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['target'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['connection_id'] = conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test[[ 'connection_id' , 'target' ]].to_csv('./result2.csv' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
